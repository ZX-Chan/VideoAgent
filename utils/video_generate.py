# -*- coding: utf-8 -*-

import os
import glob
import re
import whisper
import imageio
import numpy as np
from collections import defaultdict
from moviepy import (
    ImageClip,
    AudioFileClip,
    CompositeVideoClip,
    concatenate_videoclips,
    concatenate_audioclips,  # ä¿®æ­£: æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥
    ImageSequenceClip,
    VideoFileClip,
    AudioClip,
    vfx,
    TextClip  # ä¿®æ­£: ä¸ºæ¸…æ™°èµ·è§æ·»åŠ 
)
from moviepy.video.tools.subtitles import SubtitlesClip

# --- æ–°çš„è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨ OpenCV å’Œ Pillow åˆ›å»ºå­—å¹• ---
from PIL import Image, ImageDraw, ImageFont

def create_subtitle_clip_opencv(text, duration, clip_size, font_path="Arial.ttf", fontsize=48, txt_color=(255, 255, 255, 255), bg_color=(0, 0, 0, 128)):
    """
    ä½¿ç”¨Pillowå’ŒOpenCVåˆ›å»ºä¸€ä¸ªå­—å¹•å‰ªè¾‘ï¼Œé¿å…ä½¿ç”¨ImageMagickã€‚

    :param text: å­—å¹•æ–‡æœ¬
    :param duration: å‰ªè¾‘æ—¶é•¿
    :param clip_size: è§†é¢‘å°ºå¯¸ (width, height)
    :param font_path: å­—ä½“æ–‡ä»¶è·¯å¾„ã€‚å°è¯•ä½¿ç”¨ç³»ç»Ÿå¸¸è§å­—ä½“ã€‚
    :param fontsize: å­—ä½“å¤§å°
    :param txt_color: æ–‡å­—é¢œè‰² (R, G, B, Alpha)
    :param bg_color: èƒŒæ™¯é¢œè‰² (R, G, B, Alpha)
    :return: moviepy.ImageClip
    """
    # å°è¯•æ‰¾åˆ°ä¸€ä¸ªå¯ç”¨çš„å­—ä½“
    font_options = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
        "Arial.ttf", # åœ¨æŸäº›ç³»ç»Ÿä¸Š Pillow å¯ä»¥ç›´æ¥æ‰¾åˆ°
        "/System/Library/Fonts/Supplemental/Arial.ttf",
    ]
    
    found_font = font_path
    if not os.path.exists(font_path):
        for font in font_options:
            if os.path.exists(font):
                found_font = font
                print(f"âœ… ä½¿ç”¨å¤‡ç”¨å­—ä½“: {found_font}")
                break
    
    try:
        font = ImageFont.truetype(found_font, fontsize)
    except IOError:
        print(f"âŒ å­—ä½“ '{found_font}' åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ Pillow é»˜è®¤å­—ä½“ã€‚")
        font = ImageFont.load_default()

    # åˆ›å»ºä¸€ä¸ªé€æ˜çš„èƒŒæ™¯å›¾åƒ
    img = Image.new('RGBA', clip_size, (255, 255, 255, 0))
    draw = ImageDraw.Draw(img)

    # è®¡ç®—æ–‡æœ¬å°ºå¯¸
    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]

    # ä¸ºäº†æ›´å¥½çš„å¯è¯»æ€§ï¼Œåœ¨æ–‡å­—ä¸‹é¢ç”»ä¸€ä¸ªåŠé€æ˜çš„èƒŒæ™¯æ¡
    # ä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ padding
    padding = 10
    margin_bottom = 30  # è·ç¦»åº•éƒ¨çš„è¾¹è·
    
    # ç¡®ä¿æ–‡æœ¬ä½ç½®åœ¨è¾¹ç•Œå†…ï¼Œä½†ä¿æŒç»Ÿä¸€çš„å­—ä½“å¤§å°
    text_x = max(padding, min(clip_size[0] - text_width - padding, (clip_size[0] - text_width) / 2))
    text_y = max(padding, min(clip_size[1] - text_height - margin_bottom, clip_size[1] - text_height - margin_bottom))
    
    bg_rect_pos = [
        text_x - padding, 
        text_y - padding,
        text_x + text_width + padding, 
        text_y + text_height + padding
    ]
    # draw.rectangle(bg_rect_pos, fill=bg_color) # å¦‚æœéœ€è¦èƒŒæ™¯æ¡ï¼Œå–æ¶ˆæ­¤è¡Œæ³¨é‡Š

    # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–‡å­—ï¼ˆå¸¦æè¾¹æ•ˆæœï¼‰
    text_pos = (text_x, text_y)
    stroke_width = 2
    stroke_color = "black"
    draw.text((text_pos[0]-stroke_width, text_pos[1]), text, font=font, fill=stroke_color)
    draw.text((text_pos[0]+stroke_width, text_pos[1]), text, font=font, fill=stroke_color)
    draw.text((text_pos[0], text_pos[1]-stroke_width), text, font=font, fill=stroke_color)
    draw.text((text_pos[0], text_pos[1]+stroke_width), text, font=font, fill=stroke_color)
    draw.text(text_pos, text, font=font, fill=txt_color)

    # å°†Pillowå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œä»¥ä¾¿moviepyä½¿ç”¨
    cv_image = np.array(img)

    # åˆ›å»ºä¸€ä¸ª moviepy å‰ªè¾‘
    subtitle_clip = ImageClip(cv_image).with_duration(duration)
    return subtitle_clip

# --- è¾…åŠ©å‡½æ•°ï¼šä»ä¹‹å‰çš„è„šæœ¬ä¸­æå–å¹¶ä¼˜åŒ– ---

def _generate_srt_from_audio(audio_path: str, srt_path: str):
    """
    ä½¿ç”¨ Whisper æ¨¡å‹ä¸ºç»™å®šçš„éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆ SRT å­—å¹•ã€‚

    :param audio_path: è¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
    :param srt_path: è¾“å‡ºçš„ SRT æ–‡ä»¶è·¯å¾„ã€‚
    """
    print(f"--- å¼€å§‹ç”Ÿæˆå­—å¹•ï¼ŒéŸ³é¢‘æº: {audio_path} ---")
    try:
        # åŠ è½½æ¨¡å‹ (base æ¨¡å‹åœ¨æ€§èƒ½å’Œé€Ÿåº¦ä¸Šæ˜¯ä¸ªä¸é”™çš„èµ·ç‚¹)
        model = whisper.load_model("base")
        result = model.transcribe(audio_path, task="transcribe", language="en", fp16=False)

        def sec2timestamp(sec):
            h = int(sec // 3600)
            m = int((sec % 3600) // 60)
            s = int(sec % 60)
            ms = int((sec - int(sec)) * 1000)
            return f"{h:02}:{m:02}:{s:02},{ms:03}"

        # è¿™ä¸ªå‡½æ•°å°†çŸ­çš„å­—å¹•ç‰‡æ®µåˆå¹¶æˆæ›´æ˜“è¯»çš„å¥å­
        def merge_segments(segments, min_duration=2.0, max_chars=80):
            merged = []
            buffer = ""
            start_time = None
            end_time = None
            for i, seg in enumerate(segments):
                seg_text = seg['text'].strip()
                if not seg_text:
                    continue
                if start_time is None:
                    start_time = seg['start']

                buffer = (buffer + " " + seg_text) if buffer else seg_text
                end_time = seg['end']

                ends_with_punct = bool(re.search(r'[.!?ã€‚ï¼ï¼Ÿ]$', buffer.strip()))

                if (end_time - start_time >= min_duration) or (len(buffer) >= max_chars):
                    if ends_with_punct or len(buffer) >= max_chars:
                        # ç¡®ä¿ç»“æŸæ—¶é—´ç²¾ç¡®åæ˜ è¯­éŸ³ç»“æŸ
                        merged.append({'start': start_time, 'end': end_time, 'text': buffer})
                        buffer = ""
                        start_time = None

            if buffer and start_time is not None:
                merged.append({'start': start_time, 'end': end_time, 'text': buffer})
            return merged

        merged_segments_data = merge_segments(result["segments"])

        with open(srt_path, "w", encoding="utf-8") as f:
            for i, seg in enumerate(merged_segments_data, 1):
                start = sec2timestamp(seg["start"])
                end = sec2timestamp(seg["end"])
                text = seg["text"].strip()
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")

        print(f"--- å­—å¹•æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ°: {srt_path} ---")
        return True
    except Exception as e:
        print(f"ç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return False


# --- ä¸»å‡½æ•°ï¼šæ•´åˆäº†å›¾ç‰‡ã€éŸ³é¢‘ã€å­—å¹•å’ŒGIF ---

def create_presentation_video(
        args,
        image_dir: str,
        tts_audio_files: dict,
        page_to_section_map: dict,
        output_video_path: str,
        overlay_gif_path: str = None,
        manim_video_path: str = None,
        font_path: str = "DejaVu-Sans-Mono",  # ä½¿ç”¨ä¸€ä¸ªæ›´é€šç”¨çš„å­—ä½“åç§°
        fps: int = 24
):
    """
    å°†ä¸€ç³»åˆ—å›¾ç‰‡ã€å¯¹åº”çš„éŸ³é¢‘å’Œå­—å¹•åˆæˆä¸ºä¸€ä¸ªå¸¦è§£è¯´çš„è§†é¢‘ã€‚

    :param image_dir: åŒ…å«å›¾ç‰‡æ–‡ä»¶ï¼ˆå¦‚ 0.png, 1.png ...ï¼‰çš„ç›®å½•ã€‚
    :param tts_audio_files: å­—å…¸ï¼Œé”®æ˜¯ç« èŠ‚åï¼Œå€¼æ˜¯å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
    :param page_to_section_map: å­—å…¸ï¼Œé”®æ˜¯å›¾ç‰‡é¡µç ï¼ˆæ•´æ•°ï¼‰ï¼Œå€¼æ˜¯å¯¹åº”çš„ç« èŠ‚åã€‚
    :param output_video_path: è¾“å‡ºè§†é¢‘çš„æ–‡ä»¶è·¯å¾„ã€‚
    :param fps: è§†é¢‘çš„å¸§ç‡ã€‚
    :param overlay_gif_path: (å¯é€‰) è¦å åŠ åœ¨å³ä¸‹è§’çš„GIFæ–‡ä»¶è·¯å¾„ã€‚
    :param font_path: (å¯é€‰) ç”¨äºå­—å¹•çš„å­—ä½“æ–‡ä»¶è·¯å¾„æˆ–å­—ä½“åç§°ã€‚
    """
    # ------------------ æ­¥éª¤ 1: å‡†å¤‡å·¥ä½œå’Œæ•°æ®æ ¡éªŒ ------------------
    print("==== å¼€å§‹è§†é¢‘ç”Ÿæˆæµç¨‹ ====")

    # è·å–å›¾ç‰‡æ–‡ä»¶å¹¶æ’åº
    try:
        image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]
        image_files.sort(key=lambda x: int(os.path.splitext(x)[0]))
        num_pages = len(image_files)
        print(f"æ‰¾åˆ° {num_pages} å¼ å›¾ç‰‡ã€‚")
    except (FileNotFoundError, ValueError) as e:
        print(f"é”™è¯¯: æ— æ³•å¤„ç†å›¾ç‰‡ç›®å½• '{image_dir}'. {e}")
        return

    # ------------------ æ–°å¢æ­¥éª¤: Manimè§†é¢‘æ’å…¥ç‚¹è®¡ç®— ------------------

    manim_insert_page = -1
    should_use_manim = args.use_manim and manim_video_path and os.path.exists(manim_video_path)
    if should_use_manim:
        # æ™ºèƒ½æ’å…¥ç‚¹è®¡ç®—ï¼šä¼˜å…ˆå¯»æ‰¾ Implementation ç« èŠ‚ï¼Œå¦åˆ™æ’å…¥åˆ°æœ€åä¸€é¡µä¹‹å‰
        implementation_pages = [p for p, s in page_to_section_map.items() if s and "implementation" in s.lower()]
        if implementation_pages:
            # æ‰¾åˆ° Implementation ç« èŠ‚ï¼Œæ’å…¥åˆ°è¯¥ç« èŠ‚ä¹‹å
            manim_insert_page = max(implementation_pages) + 1
            print(f"ğŸ” æ‰¾åˆ° Implementation ç« èŠ‚ï¼ŒManimè§†é¢‘å°†æ’å…¥åœ¨ç¬¬ {manim_insert_page} é¡µ")
        else:
            # æœªæ‰¾åˆ° Implementation ç« èŠ‚ï¼Œæ’å…¥åˆ°æœ€åä¸€é¡µä¹‹å‰
            manim_insert_page = max(0, num_pages - 1)  # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°
            print(f"âš ï¸ æœªæ‰¾åˆ° Implementation ç« èŠ‚ï¼ŒManimè§†é¢‘å°†æ’å…¥åœ¨æœ€åä¸€é¡µä¹‹å‰ï¼ˆç¬¬ {manim_insert_page} é¡µï¼‰")
        
        # å®‰å…¨æ£€æŸ¥æ’å…¥ç‚¹æ˜¯å¦åˆç†
        if manim_insert_page < 0 or manim_insert_page > num_pages:
            print(f"âš ï¸ æ’å…¥ç‚¹ {manim_insert_page} è¶…å‡ºé¡µé¢èŒƒå›´ [0, {num_pages}]ï¼Œè·³è¿‡ Manim æ’å…¥ã€‚")
            should_use_manim = False
    
    elif args.use_manim:
        print(f"è­¦å‘Š: Manimè§†é¢‘è·¯å¾„ '{manim_video_path}' æ— æ•ˆæˆ–æœªæä¾›ï¼Œå°†ä¸æ’å…¥è§†é¢‘ã€‚")
        should_use_manim = False

    # ------------------ æ­¥éª¤ 2: è®¡ç®—æ¯å¼ å¹»ç¯ç‰‡çš„æ—¶é•¿å¹¶åˆå¹¶éŸ³é¢‘ ------------------
    print("\n==== æ­¥éª¤ 2: è®¡ç®—æ—¶é•¿å¹¶åˆå¹¶éŸ³é¢‘ ====")
    slide_durations = [0] * num_pages
    tts_audio_clips = []
    section_usage_count = defaultdict(int)

    for page_num in range(num_pages):
        section_name = page_to_section_map.get(page_num)
        if section_name:
            section_usage_count[section_name] += 1

    # ä¿®å¤éŸ³é¢‘å¤„ç†é€»è¾‘
    section_audio_clips = {}  # ç¼“å­˜æ¯ä¸ªsectionçš„éŸ³é¢‘æ–‡ä»¶
    section_audio_positions = defaultdict(int)  # è·Ÿè¸ªæ¯ä¸ªsectionçš„éŸ³é¢‘ä½ç½®
    
    for i in range(num_pages):
        section_name = page_to_section_map.get(i)
        if not section_name or section_name not in tts_audio_files:
            print(f"è­¦å‘Š: ç¬¬ {i} é¡µæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚æˆ–éŸ³é¢‘ï¼Œå°†ä½¿ç”¨é»˜è®¤æ—¶é•¿ 3 ç§’ã€‚")
            slide_durations[i] = 3
            # æ·»åŠ ä¸€ä¸ªçŸ­é™éŸ³ç‰‡æ®µä»¥ä¿æŒåŒæ­¥
            tts_audio_clips.append(AudioClip(lambda t: 0, duration=3, fps=44100))
            continue

        audio_path = tts_audio_files[section_name]
        try:
            # ç¼“å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œé¿å…é‡å¤åŠ è½½
            if section_name not in section_audio_clips:
                section_audio_clips[section_name] = AudioFileClip(audio_path)
            
            audio_clip = section_audio_clips[section_name]
            total_duration = audio_clip.duration
            section_count = section_usage_count[section_name]
            
            # è®¡ç®—å½“å‰é¡µé¢åº”è¯¥ä½¿ç”¨çš„éŸ³é¢‘ç‰‡æ®µ
            segment_duration = total_duration / section_count
            start_time = section_audio_positions[section_name] * segment_duration
            end_time = start_time + segment_duration
            
            # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘é•¿åº¦
            if end_time > total_duration:
                end_time = total_duration
            
            # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
            audio_segment = audio_clip.subclipped(start_time, end_time)
            actual_duration = audio_segment.duration
            slide_durations[i] = actual_duration
            tts_audio_clips.append(audio_segment)
            
            # æ›´æ–°ä½ç½®è®¡æ•°å™¨
            section_audio_positions[section_name] += 1
            
            print(f"é¡µé¢ {i} ({section_name}): åˆ†é…æ—¶é•¿ {actual_duration:.2f}s (ç‰‡æ®µ {section_audio_positions[section_name]}/{section_count})")
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶ {audio_path}ã€‚é”™è¯¯: {e}")
            slide_durations[i] = 3
            tts_audio_clips.append(AudioClip(lambda t: 0, duration=3, fps=44100))

    # åˆå¹¶TTSéŸ³é¢‘ - ä½¿ç”¨pydubæ–¹æ³•ï¼ˆæ›´å¯é ï¼‰
    print("ğŸ”Š ä½¿ç”¨pydubåˆå¹¶éŸ³é¢‘æ–‡ä»¶...")
    try:
        from pydub import AudioSegment
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºéŸ³é¢‘å¤„ç†
        temp_audio_dir = "./temp_video_assets"
        os.makedirs(temp_audio_dir, exist_ok=True)
        
        # ä½¿ç”¨pydubåˆå¹¶éŸ³é¢‘
        combined_audio = AudioSegment.empty()
        for i, audio_clip in enumerate(tts_audio_clips):
            # å°†MoviePyéŸ³é¢‘å‰ªè¾‘è½¬æ¢ä¸ºä¸´æ—¶æ–‡ä»¶
            temp_audio_path = os.path.join(temp_audio_dir, f"temp_audio_{i}.mp3")
            # ä¿®å¤ï¼šæ–°ç‰ˆæœ¬MoviePyçš„write_audiofileå‚æ•°å˜åŒ–
            audio_clip.write_audiofile(temp_audio_path, logger=None)
            
            # ä½¿ç”¨pydubåŠ è½½å¹¶åˆå¹¶
            segment = AudioSegment.from_mp3(temp_audio_path)
            combined_audio += segment
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_audio_path)
        
        # å¦‚æœéœ€è¦ï¼Œæ’å…¥Manimçš„é™éŸ³ç‰‡æ®µ
        #lbx modified
        # if should_use_manim:
        #     print("æ­£åœ¨å°†é™éŸ³ç‰‡æ®µæ’å…¥éŸ³é¢‘è½¨é“ä»¥åŒ¹é…Manimè§†é¢‘...")
        #     manim_clip_for_audio = VideoFileClip(manim_video_path)
        #     manim_duration = manim_clip_for_audio.duration
        #     silent_segment = AudioSegment.silent(duration=int(manim_duration * 1000))  # pydubä½¿ç”¨æ¯«ç§’

        #     # è®¡ç®—éŸ³é¢‘æ’å…¥ç‚¹
        #     audio_insertion_time = sum(slide_durations[:manim_insert_page])
        #     print(f"éŸ³é¢‘æ’å…¥ç‚¹: {audio_insertion_time:.2f}s")

        #     # åˆ†å‰²å¹¶é‡ç»„éŸ³é¢‘
        #     insertion_ms = int(audio_insertion_time * 1000)
        #     if insertion_ms < len(combined_audio):
        #         part1 = combined_audio[:insertion_ms]
        #         part2 = combined_audio[insertion_ms:]
        #         combined_audio = part1 + silent_segment + part2
        #     else:
        #         # å¦‚æœæ’å…¥ç‚¹è¶…å‡ºéŸ³é¢‘é•¿åº¦ï¼Œç›´æ¥æ·»åŠ é™éŸ³
        #         combined_audio = combined_audio + silent_segment
        #####start

        if should_use_manim:
            print("ğŸ”Š æ­£åœ¨å¤„ç†Manimè§†é¢‘çš„éŸ³è½¨...")

            # ä¿®æ­£ç¬¬ä¸€æ­¥ï¼šæ— è®ºå¦‚ä½•ï¼Œå…ˆåŠ è½½Manimè§†é¢‘å‰ªè¾‘ä»¥è·å–ä¿¡æ¯
            manim_clip_for_audio = VideoFileClip(manim_video_path)
            manim_duration_ms = int(manim_clip_for_audio.duration * 1000)

            # ç°åœ¨æ£€æŸ¥æˆ‘ä»¬è‡ªå®šä¹‰çš„éŸ³è½¨
            manim_audio_path = tts_audio_files.get("Manim_Animation", tts_audio_files.get("manim_narration1")) # å°è¯•ä¸¤ä¸ªå¯èƒ½çš„é”®å

            if manim_audio_path and os.path.exists(manim_audio_path):
                print(f"âœ… æ‰¾åˆ°ManiméŸ³è½¨: {manim_audio_path}")
                manim_audio_segment = AudioSegment.from_mp3(manim_audio_path)

                # å¯é€‰ï¼šå¦‚æœéŸ³é¢‘æ—¶é•¿ä¸è§†é¢‘æ—¶é•¿å·®å¼‚è¿‡å¤§ï¼Œå¯ä»¥æˆªæ–­æˆ–å¡«å……
                # è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°æˆªæ–­éŸ³é¢‘ä»¥åŒ¹é…è§†é¢‘æ—¶é•¿
                if len(manim_audio_segment) > manim_duration_ms:
                    manim_audio_segment = manim_audio_segment[:manim_duration_ms]

            else:
                print("âš ï¸ æœªæ‰¾åˆ°è‡ªå®šä¹‰ManiméŸ³è½¨ï¼Œå°†ä½¿ç”¨é™éŸ³ã€‚")
                manim_audio_segment = AudioSegment.silent(duration=manim_duration_ms)

            # ä¿®æ­£ç¬¬äºŒæ­¥ï¼šåœ¨ä½¿ç”¨å®Œå‰ªè¾‘åï¼ŒåŠæ—¶å…³é—­
            manim_clip_for_audio.close()

            # è®¡ç®—éŸ³é¢‘æ’å…¥ç‚¹
            audio_insertion_time = sum(slide_durations[:manim_insert_page])
            print(f"éŸ³é¢‘æ’å…¥ç‚¹: {audio_insertion_time:.2f}s")

            # åˆ†å‰²å¹¶é‡ç»„éŸ³é¢‘
            insertion_ms = int(audio_insertion_time * 1000)
            if insertion_ms < len(combined_audio):
                part1 = combined_audio[:insertion_ms]
                part2 = combined_audio[insertion_ms:]
                combined_audio = part1 + manim_audio_segment + part2
            else:
                combined_audio = combined_audio + manim_audio_segment
        #####end
            manim_clip_for_audio.close()
        
        # å°†åˆå¹¶åçš„éŸ³é¢‘ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_combined_audio_path = os.path.join(temp_audio_dir, "combined_audio.mp3")
        combined_audio.export(temp_combined_audio_path, format="mp3")
        
        # ä»ä¸´æ—¶æ–‡ä»¶åˆ›å»ºMoviePyéŸ³é¢‘å‰ªè¾‘
        full_audio_track = AudioFileClip(temp_combined_audio_path)
        print(f"âœ… éŸ³é¢‘åˆå¹¶æˆåŠŸï¼Œæ€»æ—¶é•¿: {full_audio_track.duration:.2f}s")
        
    except Exception as e:
        print(f"âŒ pydubéŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°MoviePyéŸ³é¢‘åˆå¹¶æ–¹æ³•...")
        
        # å›é€€åˆ°åŸæ¥çš„MoviePyæ–¹æ³•
        concatenated_tts_audio = concatenate_audioclips(tts_audio_clips)
        
        # å¦‚æœéœ€è¦ï¼Œæ’å…¥Manimçš„é™éŸ³ç‰‡æ®µ
        if should_use_manim:
            print("æ­£åœ¨å°†é™éŸ³ç‰‡æ®µæ’å…¥éŸ³é¢‘è½¨é“ä»¥åŒ¹é…Manimè§†é¢‘...")
            manim_clip_for_audio = VideoFileClip(manim_video_path)
            manim_duration = manim_clip_for_audio.duration
            silent_audio = AudioClip(lambda t: 0, duration=manim_duration, fps=44100)

            # è®¡ç®—éŸ³é¢‘æ’å…¥ç‚¹
            audio_insertion_time = sum(slide_durations[:manim_insert_page])
            print(f"éŸ³é¢‘æ’å…¥ç‚¹: {audio_insertion_time:.2f}s")

            # åˆ†å‰²å¹¶é‡ç»„éŸ³é¢‘
            if audio_insertion_time < concatenated_tts_audio.duration:
                # ä¿®å¤ï¼šæ–°ç‰ˆæœ¬MoviePyä½¿ç”¨subclippedè€Œä¸æ˜¯subclip
                audio_part1 = concatenated_tts_audio.subclipped(0, audio_insertion_time)
                audio_part2 = concatenated_tts_audio.subclipped(audio_insertion_time)
                full_audio_track = concatenate_audioclips([audio_part1, silent_audio, audio_part2])
            else:
                full_audio_track = concatenate_audioclips([concatenated_tts_audio, silent_audio])
            
            manim_clip_for_audio.close()
        else:
            full_audio_track = concatenated_tts_audio

    total_duration = full_audio_track.duration
    print(f"éŸ³é¢‘è½¨é“æ„å»ºå®Œæˆï¼Œæ€»æ—¶é•¿: {total_duration:.2f}s")
    
    # éªŒè¯éŸ³é¢‘æ˜¯å¦æœ‰æ•ˆ
    if total_duration <= 0:
        print("âŒ é”™è¯¯: éŸ³é¢‘è½¨é“æ—¶é•¿ä¸º0ï¼Œå°†ä½¿ç”¨é™éŸ³")
        full_audio_track = AudioClip(lambda t: 0, duration=sum(slide_durations), fps=44100)
    else:
        print(f"âœ… éŸ³é¢‘è½¨é“éªŒè¯é€šè¿‡ï¼Œæ€»æ—¶é•¿: {total_duration:.2f}s")
        
        # é¢å¤–éªŒè¯ï¼šæ£€æŸ¥éŸ³é¢‘æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆä¸æ˜¯å®Œå…¨é™éŸ³ï¼‰
        try:
            # å°è¯•è·å–éŸ³é¢‘çš„æŒ¯å¹…ä¿¡æ¯
            test_frame = full_audio_track.get_frame(0.1)  # è·å–0.1ç§’å¤„çš„å¸§
            if isinstance(test_frame, np.ndarray):
                max_amplitude = np.max(np.abs(test_frame))
                print(f"âœ… éŸ³é¢‘æŒ¯å¹…æ£€æŸ¥: æœ€å¤§æŒ¯å¹… = {max_amplitude:.6f}")
                if max_amplitude < 0.001:  # å¦‚æœæŒ¯å¹…å¤ªå°ï¼Œå¯èƒ½æ˜¯é™éŸ³
                    print("âš ï¸ è­¦å‘Š: éŸ³é¢‘æŒ¯å¹…å¾ˆå°ï¼Œå¯èƒ½æ˜¯é™éŸ³")
            else:
                print("âœ… éŸ³é¢‘å¸§æ£€æŸ¥é€šè¿‡")
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘æŒ¯å¹…æ£€æŸ¥å¤±è´¥: {e}")

    # ------------------ æ­¥éª¤ 3: ç”Ÿæˆå­—å¹•æ–‡ä»¶ ------------------
    print("\n==== æ­¥éª¤ 3: ç”Ÿæˆå­—å¹• ====")
    temp_dir = "./temp_video_assets"
    os.makedirs(temp_dir, exist_ok=True)
    temp_audio_path = os.path.join(temp_dir, "full_audio.mp3")
    temp_srt_path = os.path.join(temp_dir, "subtitles.srt")

    # æ·»åŠ éŸ³é¢‘è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ”Š éŸ³é¢‘è°ƒè¯•ä¿¡æ¯:")
    print(f"   - éŸ³é¢‘è½¨é“æ—¶é•¿: {full_audio_track.duration:.2f}s")
    print(f"   - éŸ³é¢‘é‡‡æ ·ç‡: {full_audio_track.fps if hasattr(full_audio_track, 'fps') else 'N/A'}")
    print(f"   - ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {temp_audio_path}")
    
    # æ£€æŸ¥åŸå§‹TTSéŸ³é¢‘æ–‡ä»¶
    print(f"ğŸ” æ£€æŸ¥åŸå§‹TTSéŸ³é¢‘æ–‡ä»¶:")
    for section_name, audio_path in tts_audio_files.items():
        if os.path.exists(audio_path):
            file_size = os.path.getsize(audio_path)
            print(f"   - {section_name}: {file_size} bytes")
            
            # å°è¯•åŠ è½½å¹¶æ£€æŸ¥éŸ³é¢‘
        try:
            test_audio = AudioFileClip(audio_path)
            # ä¿®å¤ï¼šé€šè¿‡ä¼ é€’ä¸€ä¸ªæ˜ç¡®çš„æ—¶é—´æ®µæ¥è§„é¿ to_soundarray çš„ bug
            audio_array = test_audio.get_frame(t=0.1) # è·å–ä¸€ä¸ªæ ·æœ¬å¸§
            # æˆ‘ä»¬ä¸å†å°è¯•è¯»å–æ•´ä¸ªæ•°ç»„ï¼Œè€Œæ˜¯ç›´æ¥æ£€æŸ¥æ—¶é•¿
            print(f"     - æ—¶é•¿: {test_audio.duration:.2f}s (æŒ¯å¹…æ£€æŸ¥å·²è·³è¿‡)")
            test_audio.close()
        except Exception as e:
            print(f"     - æ— æ³•åŠ è½½éŸ³é¢‘: {e}")
            try:
                test_audio = AudioFileClip(audio_path)
                print(f"     - æ—¶é•¿: {test_audio.duration:.2f}s (æ— æ³•è·å–æŒ¯å¹…)")
                test_audio.close()
            except:
                print(f"     - å®Œå…¨æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶")
        else:
            print(f"   - {section_name}: æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é™éŸ³ï¼‰
        try:
            # æˆ‘ä»¬åœ¨è¿™é‡Œåªåšæœ€ç®€å•çš„æ£€æŸ¥ï¼Œå› ä¸ºä¸»è¦é—®é¢˜æ˜¯ to_soundarray
            if full_audio_track.duration > 0:
                print(f"ğŸ”Š éŸ³é¢‘è½¨é“æœ‰æ•ˆï¼Œæ—¶é•¿: {full_audio_track.duration:.2f}s")
                full_audio_track.write_audiofile(temp_audio_path)
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶å†™å…¥æˆåŠŸ: {temp_audio_path}")
            else:
                print("âŒ éŸ³é¢‘è½¨é“æ—¶é•¿ä¸º0")
                temp_audio_path = None
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
            temp_audio_path = None
            
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if temp_audio_path and os.path.exists(temp_audio_path):
            file_size = os.path.getsize(temp_audio_path)
            print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„åŒ…å«éŸ³é¢‘æ•°æ®
            if file_size < 1000:  # å°äº1KBå¯èƒ½æ˜¯ç©ºæ–‡ä»¶
                print("âš ï¸ è­¦å‘Š: éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘æ•°æ®")
            else:
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤§å°æ­£å¸¸: {file_size} bytes")
        else:
            print("âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
        temp_audio_path = None
    
    if temp_audio_path and os.path.exists(temp_audio_path):
        # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æœ‰å£°éŸ³
        try:
            import subprocess
            # ä½¿ç”¨ ffprobe æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
            result = subprocess.run(['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', temp_audio_path], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                duration = float(result.stdout.strip())
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶éªŒè¯æˆåŠŸï¼Œæ—¶é•¿: {duration:.2f}s")
                
                # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(temp_audio_path)
                if file_size > 10000:  # å¤§äº10KB
                    print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤§å°æ­£å¸¸: {file_size} bytes")
                    
                    # é¢å¤–éªŒè¯ï¼šå°è¯•åŠ è½½éŸ³é¢‘æ–‡ä»¶ç¡®ä¿å®ƒæ˜¯æœ‰æ•ˆçš„
                    try:
                        test_audio = AudioFileClip(temp_audio_path)
                        print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¯ä»¥æ­£å¸¸åŠ è½½ï¼Œæ—¶é•¿: {test_audio.duration:.2f}s")
                        test_audio.close()
                        
                        if not _generate_srt_from_audio(temp_audio_path, temp_srt_path):
                            print("å­—å¹•ç”Ÿæˆå¤±è´¥ï¼Œè§†é¢‘å°†ä¸åŒ…å«å­—å¹•ã€‚")
                            temp_srt_path = None
                    except Exception as e:
                        print(f"âŒ éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                        temp_srt_path = None
                else:
                    print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶å¤ªå°: {file_size} bytesï¼Œå¯èƒ½æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘")
                    temp_srt_path = None
            else:
                print("âŒ éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥")
                temp_srt_path = None
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶éªŒè¯å‡ºé”™: {e}")
            temp_srt_path = None
    else:
        print("âŒ æ— æ³•ç”Ÿæˆå­—å¹•ï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        temp_srt_path = None

    # ------------------ æ­¥éª¤ 4: ä»å›¾ç‰‡åˆ›å»ºè§†é¢‘å‰ªè¾‘ ------------------
    print("\n==== æ­¥éª¤ 4: åˆ›å»ºä¸»è§†é¢‘è½¨é“ ====")
    video_segments = []
    target_size = None  # ç”¨äºå­˜å‚¨å¹»ç¯ç‰‡çš„ç»Ÿä¸€å°ºå¯¸
    for i, image_file in enumerate(image_files):
        image_path = os.path.join(image_dir, image_file)
        clip = ImageClip(image_path).with_duration(slide_durations[i])
        if target_size is None:
            target_size = clip.size
            print(f"æ‰€æœ‰è§†é¢‘å‰ªè¾‘çš„ç›®æ ‡å°ºå¯¸è®¾ç½®ä¸º: {target_size}")
        video_segments.append(clip)

    if should_use_manim:
        print(f"æ­£åœ¨åŠ è½½Manimè§†é¢‘: {manim_video_path}")
        manim_clip = VideoFileClip(manim_video_path)
        if manim_clip.size != target_size and target_size is not None:
            print(f"æ­£åœ¨å°†Manimè§†é¢‘ä» {manim_clip.size} è°ƒæ•´åˆ° {target_size}")
            manim_clip = manim_clip.resized(target_size)
        video_segments.insert(manim_insert_page, manim_clip)

    main_clip = concatenate_videoclips(video_segments, method="compose")
    main_clip.fps = fps
    
    # ç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘æ—¶é•¿åŒ¹é…
    video_duration = main_clip.duration
    audio_duration = full_audio_track.duration
    
    print(f"è§†é¢‘æ—¶é•¿: {video_duration:.2f}s, éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}s")
    
    # å¦‚æœæ—¶é•¿ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´
    if abs(video_duration - audio_duration) > 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
        print(f"âš ï¸ éŸ³é¢‘å’Œè§†é¢‘æ—¶é•¿ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´...")
        if video_duration > audio_duration:
            # è§†é¢‘æ›´é•¿ï¼Œå»¶é•¿éŸ³é¢‘
            padding_duration = video_duration - audio_duration
            padding_audio = AudioClip(lambda t: 0, duration=padding_duration, fps=44100)
            full_audio_track = concatenate_audioclips([full_audio_track, padding_audio])
        else:
            # éŸ³é¢‘æ›´é•¿ï¼Œæˆªæ–­éŸ³é¢‘
            full_audio_track = full_audio_track.subclipped(0, video_duration)
    
    #main_clip = main_clip.set_audio(full_audio_track)  # å°†å®Œæ•´éŸ³è½¨é™„åŠ åˆ°è§†é¢‘
    
    

    # ------------------ æ­¥éª¤ 5: å åŠ å­—å¹•å’ŒGIF ------------------
    print("\n==== æ­¥éª¤ 5: å åŠ å­—å¹•å’Œå¯é€‰çš„GIF ====")
    clips_to_composite = [main_clip]

    # --- æ–°çš„å­—å¹•æ·»åŠ é€»è¾‘ (Plan B) ---
    if temp_srt_path and os.path.exists(temp_srt_path):
        print("æ­£åœ¨ä½¿ç”¨ OpenCV å’Œ Pillow æ·»åŠ å­—å¹•...")
        try:
            from moviepy.video.tools.subtitles import SubtitlesClip
            from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
            import pysrt # éœ€è¦å®‰è£…: pip install pysrt

            subs = pysrt.open(temp_srt_path)
            subtitle_clips = []
            fade_duration = 0.2  # å‡å°‘æ·¡å‡ºæ—¶é—´ï¼Œé¿å…é‡å 
            min_gap = 0.1  # å­—å¹•ä¹‹é—´çš„æœ€å°é—´éš”
            
            for i, sub in enumerate(subs):
                start_time = sub.start.to_time().hour * 3600 + sub.start.to_time().minute * 60 + sub.start.to_time().second + sub.start.to_time().microsecond / 1e6
                end_time = sub.end.to_time().hour * 3600 + sub.end.to_time().minute * 60 + sub.end.to_time().second + sub.end.to_time().microsecond / 1e6
                
                # ç¡®ä¿å­—å¹•åœ¨è¯­éŸ³ç»“æŸåç«‹å³æ¶ˆå¤±ï¼Œä¸ç»™ä¸‹ä¸€å¥ç•™é‡å æ—¶é—´
                display_duration = (end_time - start_time)
                
                # å¦‚æœä¸‹ä¸€å¥å­—å¹•å¼€å§‹æ—¶é—´å¤ªè¿‘ï¼Œæå‰ç»“æŸå½“å‰å­—å¹•
                if i < len(subs) - 1:
                    next_start = subs[i+1].start.to_time().hour * 3600 + subs[i+1].start.to_time().minute * 60 + subs[i+1].start.to_time().second + subs[i+1].start.to_time().microsecond / 1e6
                    if next_start - end_time < min_gap:
                        display_duration = (end_time - start_time) - (min_gap - (next_start - end_time))
                        display_duration = max(display_duration, 0.1)  # ç¡®ä¿è‡³å°‘æ˜¾ç¤º0.1ç§’
                
                # ä½¿ç”¨æˆ‘ä»¬çš„æ–°å‡½æ•°åˆ›å»ºå‰ªè¾‘ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å­—ä½“å¤§å°
                text_clip = create_subtitle_clip_opencv(
                    sub.text, 
                    display_duration, 
                    main_clip.size,
                    fontsize=36  # ç»Ÿä¸€ä½¿ç”¨36å·å­—ä½“
                )
                
                # æ·»åŠ æ·¡å‡ºæ•ˆæœï¼šåœ¨è¯­éŸ³ç»“æŸå‰å¼€å§‹æ·¡å‡ºï¼Œç¡®ä¿ä¸é‡å 
                fade_start_time = max(0, display_duration - fade_duration)
                try:
                    # ä½¿ç”¨fadeæ–¹æ³•ï¼Œåœ¨å­—å¹•ç»“æŸå‰å¼€å§‹æ·¡å‡º
                    text_clip_with_fade = text_clip.fade(0, fade_duration)
                except Exception as e:
                    try:
                        # å°è¯•ä½¿ç”¨fadeoutæ–¹æ³•
                        text_clip_with_fade = text_clip.fadeout(fade_duration)
                    except AttributeError:
                        try:
                            # å°è¯•ä½¿ç”¨vfx.fadeoutæ–¹æ³•
                            text_clip_with_fade = vfx.fadeout(text_clip, fade_duration)
                        except AttributeError:
                            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨åŸå‰ªè¾‘ï¼ˆæ— æ·¡å‡ºæ•ˆæœï¼‰
                            print(f"âš ï¸ è­¦å‘Š: æ— æ³•åº”ç”¨æ·¡å‡ºæ•ˆæœï¼Œå­—å¹•å°†ç›´æ¥æ¶ˆå¤± (é”™è¯¯: {e})")
                            text_clip_with_fade = text_clip
                
                # è®¾ç½®å‰ªè¾‘çš„å¼€å§‹æ—¶é—´å¹¶æ·»åŠ åˆ°åˆ—è¡¨
                subtitle_clips.append(text_clip_with_fade.with_start(start_time))

            # å°†æ‰€æœ‰å­—å¹•å‰ªè¾‘å’Œä¸»è§†é¢‘åˆæˆä¸ºä¸€ä¸ª
            clips_to_composite.extend(subtitle_clips)
            print("âœ… å­—å¹•æ·»åŠ æˆåŠŸ (ä½¿ç”¨OpenCVæ–¹æ¡ˆï¼Œå¸¦æ·¡å‡ºæ•ˆæœ)")

        except Exception as e:
            print(f"âŒ ä½¿ç”¨OpenCVæ–¹æ¡ˆæ·»åŠ å­—å¹•æ—¶å¤±è´¥: {e}")

    # æ·»åŠ GIF
    if overlay_gif_path:
        print(f"æ­£åœ¨æ·»åŠ GIF: {overlay_gif_path}")
        try:
            # ä¿®æ­£: ä½¿ç”¨ imageio æ­£ç¡®è¯»å–GIFæ–‡ä»¶
            gif_reader = imageio.get_reader(overlay_gif_path)
            # ä»GIFå…ƒæ•°æ®è·å–fpsï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨è§†é¢‘çš„fps
            gif_fps = gif_reader.get_meta_data().get('fps', fps)
            gif_frames = [frame for frame in gif_reader]

            # ä»å¸§åˆ—è¡¨åˆ›å»ºå‰ªè¾‘
            gif_clip = ImageSequenceClip(gif_frames, fps=gif_fps)

            resized_gif = gif_clip.resized(height=main_clip.h * 0.25)  # GIFé«˜åº¦ä¸ºè§†é¢‘çš„25%
            # ä¿®å¤ï¼šæ–°ç‰ˆæœ¬MoviePyä¸­fxæ–¹æ³•å¯èƒ½ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨loopæ–¹æ³•
            try:
                looped_gif = resized_gif.fx(vfx.loop, duration=main_clip.duration)
            except AttributeError:
                # å¦‚æœfxä¸å¯ç”¨ï¼Œæ‰‹åŠ¨åˆ›å»ºå¾ªç¯
                num_loops = int(main_clip.duration / resized_gif.duration) + 1
                looped_gif = concatenate_videoclips([resized_gif] * num_loops)
                looped_gif = looped_gif.subclipped(0, main_clip.duration)
            positioned_gif = looped_gif.with_position(("right", "bottom"))
            clips_to_composite.append(positioned_gif)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½æˆ–å¤„ç†GIF '{overlay_gif_path}'. é”™è¯¯: {e}")

    # å…ˆç»™ä¸»è§†é¢‘å‰ªè¾‘é™„åŠ éŸ³é¢‘
    print("ğŸ”Š æ­£åœ¨ç»™ä¸»è§†é¢‘å‰ªè¾‘é™„åŠ éŸ³é¢‘...")
    main_clip_with_audio = main_clip.with_audio(full_audio_track)
    
    # ç„¶ååˆ›å»ºæœ€ç»ˆçš„åˆæˆå‰ªè¾‘
    final_clip = CompositeVideoClip([main_clip_with_audio] + clips_to_composite[1:])  # ä¿æŒä¸»è§†é¢‘çš„éŸ³é¢‘ï¼Œå…¶ä»–å…ƒç´ å åŠ 
    # final_clip.set_duration(main_clip.duration)

    # ------------------ æ­¥éª¤ 6: å†™å…¥æœ€ç»ˆè§†é¢‘æ–‡ä»¶ ------------------
    print("\n==== æ­¥éª¤ 6: æ­£åœ¨å†™å…¥æœ€ç»ˆè§†é¢‘æ–‡ä»¶... (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´) ====")
    print(output_video_path, fps)
    
    # ç¡®ä¿éŸ³é¢‘æ­£ç¡®é™„åŠ åˆ°æœ€ç»ˆå‰ªè¾‘
    print("ğŸ”Š æ­£åœ¨éªŒè¯æœ€ç»ˆå‰ªè¾‘çš„éŸ³é¢‘...")
    final_clip_with_audio = final_clip  # éŸ³é¢‘å·²ç»åœ¨ä¸»è§†é¢‘ä¸­
    
    # vvvv åœ¨è¿™é‡Œæ·»åŠ æœ€ç»ˆè°ƒè¯•ä»£ç  vvvv
    print("--- FINAL CLIP DEBUG INFO ---")
    print(f"Final clip duration = {final_clip_with_audio.duration}")
    print(f"Final clip size (width, height) = {final_clip_with_audio.size}")
    print(f"Has audio? {'Yes' if final_clip_with_audio.audio is not None else 'No'}")
    if final_clip_with_audio.audio is not None:
        print(f"Audio duration = {final_clip_with_audio.audio.duration}")
        print(f"Audio fps = {final_clip_with_audio.audio.fps if hasattr(final_clip_with_audio.audio, 'fps') else 'N/A'}")
        
       
    
    print('fps:', fps)
    
    # ä½¿ç”¨æ›´æ˜ç¡®çš„éŸ³é¢‘å‚æ•°
    try:
        # ä¿®å¤ï¼šæ–°ç‰ˆæœ¬MoviePyçš„write_videofileå‚æ•°å˜åŒ–
        final_clip_with_audio.write_videofile(
            output_video_path,
            codec="libx264",
            audio_codec="aac",
            temp_audiofile='temp-audio.m4a', 
            remove_temp=True,
            threads=4, 
            logger='bar',
            ffmpeg_params=["-strict", "-2"]  # æ·»åŠ ffmpegå‚æ•°ä»¥ç¡®ä¿éŸ³é¢‘æ­£ç¡®å¤„ç†
        )
        print(f"\nè§†é¢‘æˆåŠŸåˆ›å»ºï¼å·²ä¿å­˜è‡³ï¼š{output_video_path}")
    except Exception as e:
        print(f"âŒ è§†é¢‘å†™å…¥å¤±è´¥: {e}")
        print("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
        
        # å¤‡ç”¨æ–¹æ³•ï¼šå…ˆç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘ï¼Œç„¶åç”¨ffmpegåˆå¹¶
        try:
            # ç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘
            temp_video_path = output_video_path.replace('.mp4', '_temp.mp4')
            # ä¿®å¤ï¼šæ–°ç‰ˆæœ¬MoviePyçš„write_videofileå‚æ•°å˜åŒ–
            final_clip_with_audio.write_videofile(
                temp_video_path,
                codec="libx264",
                audio=False,  # ä¸åŒ…å«éŸ³é¢‘
                temp_audiofile=None,
                remove_temp=True,
                threads=4, 
                logger='bar'
            )
            
            # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
            import subprocess
            cmd = [
                'ffmpeg', '-y',
                '-i', temp_video_path,
                '-i', temp_audio_path,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-strict', '-2',
                output_video_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… å¤‡ç”¨æ–¹æ³•æˆåŠŸï¼è§†é¢‘å·²ä¿å­˜è‡³ï¼š{output_video_path}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)
            else:
                print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥äº†: {result.stderr}")
        except Exception as backup_e:
            print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥äº†: {backup_e}")

    # print("æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    # full_audio_track.close()
    # for clip in tts_audio_clips:
    #     clip.close()
    # if os.path.exists(temp_audio_path): os.remove(temp_audio_path)
    # if os.path.exists(temp_srt_path): os.remove(temp_srt_path)
    # if os.path.exists(temp_dir): os.rmdir(temp_dir)


if __name__ == '__main__':
    # =================================================================
    # --- ä½¿ç”¨ç¤ºä¾‹ ---
    # å‡è®¾ä½ çš„å›¾ç‰‡åœ¨ './data/my_poster/images/' ç›®å½•ä¸‹ï¼Œå‘½åä¸º 0.png, 1.png ...
    # =================================================================

    # 1. å®šä¹‰ä½ çš„æ•°æ®ç»“æ„
    tts_audio_files_example = {
        "Poster Title & Author": "./contents/tts/section_01_Poster Title & Author.mp3",
        "Abstract": "./contents/tts/section_02_Abstract.mp3",
        "Introduction": "./contents/tts/section_03_Introduction.mp3",
        "Related Work": "./contents/tts/section_04_Related Work.mp3",
        "Methodology": "./contents/tts/section_05_Methodology.mp3",
        "Experimental Settings": "./contents/tts/section_06_Experimental Settings.mp3",
        "Experimental Results": "./contents/tts/section_07_Experimental Results.mp3",
        "Conclusion": "./contents/tts/section_08_Conclusion.mp3"
    }

    page_to_section_map_example = {
        0: 'Poster Title & Author',
        1: 'Abstract',
        2: 'Introduction',
        3: 'Related Work',
        4: 'Methodology',  # Methodologyçš„ç¬¬ä¸€é¡µ
        5: 'Methodology',  # Methodologyçš„ç¬¬äºŒé¡µ
        6: 'Experimental Settings',
        7: 'Experimental Results',
        8: 'Conclusion'
    }

    # 2. è®¾ç½®è·¯å¾„
    poster_name = "MyAwesomePoster"  # å®šä¹‰ä½ çš„é¡¹ç›®å
    image_directory = f'./data/{poster_name}/images'
    gif_file_path = f'./data/{poster_name}/kq.gif'  # å¦‚æœæ²¡æœ‰GIFï¼Œè®¾ä¸º None
    output_file_path = f'./output/{poster_name}_presentation.mp4'

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)

    # --- æ¨¡æ‹Ÿåˆ›å»ºä¸€äº›æ–‡ä»¶ç”¨äºæµ‹è¯• ---
    print("--- æ­£åœ¨åˆ›å»ºç”¨äºæµ‹è¯•çš„è™šæ‹Ÿæ–‡ä»¶ ---")
    os.makedirs(image_directory, exist_ok=True)
    for i in range(len(page_to_section_map_example)):
        # åˆ›å»ºç©ºç™½å›¾ç‰‡
        from PIL import Image

        img = Image.new('RGB', (1920, 1080), color='darkblue')
        img.save(os.path.join(image_directory, f'{i}.png'))

    os.makedirs("./contents/tts", exist_ok=True)
    for section, path in tts_audio_files_example.items():
        # åˆ›å»ºé™éŸ³éŸ³é¢‘
        from pydub import AudioSegment

        silence = AudioSegment.silent(duration=5000 if "Methodology" not in section else 10000)  # ç»™æ–¹æ³•è®ºæ›´é•¿çš„æ—¶é—´
        silence.export(path, format="mp3")
    print("--- è™šæ‹Ÿæ–‡ä»¶åˆ›å»ºå®Œæ¯• ---\n")
    # --- æ¨¡æ‹Ÿæ–‡ä»¶åˆ›å»ºç»“æŸ ---

    # 3. è°ƒç”¨ä¸»å‡½æ•°
    create_presentation_video(
        image_dir=image_directory,
        tts_audio_files=tts_audio_files_example,
        page_to_section_map=page_to_section_map_example,
        output_video_path=output_file_path,
        overlay_gif_path=None  # æš‚æ—¶ç¦ç”¨GIFæµ‹è¯•
        # overlay_gif_path=gif_file_path # å¦‚æœä½ æœ‰GIFæ–‡ä»¶ï¼Œè¯·å–æ¶ˆæ­¤è¡Œæ³¨é‡Š
    )

