# -*- coding: utf-8 -*-

import os
import glob
import re
import whisper
import imageio
import numpy as np
from collections import defaultdict
from moviepy.editor import (
    ImageClip,
    AudioFileClip,
    CompositeVideoClip,
    concatenate_videoclips,
    concatenate_audioclips,  # ä¿®æ­£: æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥
    ImageSequenceClip,
    VideoFileClip,
    AudioClip,
    vfx,
    TextClip  # ä¿®æ­£: ä¸ºæ¸…æ™°èµ·è§æ·»åŠ 
)
from moviepy.video.tools.subtitles import SubtitlesClip

# --- æ–°çš„è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨ OpenCV å’Œ Pillow åˆ›å»ºå­—å¹• ---
from PIL import Image, ImageDraw, ImageFont

def create_subtitle_clip_opencv(text, duration, clip_size, font_path="Arial.ttf", fontsize=48, txt_color=(255, 255, 255, 255), bg_color=(0, 0, 0, 128)):
    """
    ä½¿ç”¨Pillowå’ŒOpenCVåˆ›å»ºä¸€ä¸ªå­—å¹•å‰ªè¾‘ï¼Œé¿å…ä½¿ç”¨ImageMagickã€‚

    :param text: å­—å¹•æ–‡æœ¬
    :param duration: å‰ªè¾‘æ—¶é•¿
    :param clip_size: è§†é¢‘å°ºå¯¸ (width, height)
    :param font_path: å­—ä½“æ–‡ä»¶è·¯å¾„ã€‚å°è¯•ä½¿ç”¨ç³»ç»Ÿå¸¸è§å­—ä½“ã€‚
    :param fontsize: å­—ä½“å¤§å°
    :param txt_color: æ–‡å­—é¢œè‰² (R, G, B, Alpha)
    :param bg_color: èƒŒæ™¯é¢œè‰² (R, G, B, Alpha)
    :return: moviepy.ImageClip
    """
    # å°è¯•æ‰¾åˆ°ä¸€ä¸ªå¯ç”¨çš„å­—ä½“
    font_options = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
        "Arial.ttf", # åœ¨æŸäº›ç³»ç»Ÿä¸Š Pillow å¯ä»¥ç›´æ¥æ‰¾åˆ°
        "/System/Library/Fonts/Supplemental/Arial.ttf",
    ]
    
    found_font = font_path
    if not os.path.exists(font_path):
        for font in font_options:
            if os.path.exists(font):
                found_font = font
                print(f"âœ… ä½¿ç”¨å¤‡ç”¨å­—ä½“: {found_font}")
                break
    
    try:
        font = ImageFont.truetype(found_font, fontsize)
    except IOError:
        print(f"âŒ å­—ä½“ '{found_font}' åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ Pillow é»˜è®¤å­—ä½“ã€‚")
        font = ImageFont.load_default()

    # åˆ›å»ºä¸€ä¸ªé€æ˜çš„èƒŒæ™¯å›¾åƒ
    img = Image.new('RGBA', clip_size, (255, 255, 255, 0))
    draw = ImageDraw.Draw(img)

    # è®¡ç®—æ–‡æœ¬å°ºå¯¸
    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]

    # ä¸ºäº†æ›´å¥½çš„å¯è¯»æ€§ï¼Œåœ¨æ–‡å­—ä¸‹é¢ç”»ä¸€ä¸ªåŠé€æ˜çš„èƒŒæ™¯æ¡
    # ä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ padding
    padding = 10
    bg_rect_pos = [
        ((clip_size[0] - text_width) / 2) - padding, 
        clip_size[1] - text_height - 30 - padding, # 30 æ˜¯è·ç¦»åº•éƒ¨çš„è¾¹è·
        ((clip_size[0] + text_width) / 2) + padding, 
        clip_size[1] - 30 + padding
    ]
    # draw.rectangle(bg_rect_pos, fill=bg_color) # å¦‚æœéœ€è¦èƒŒæ™¯æ¡ï¼Œå–æ¶ˆæ­¤è¡Œæ³¨é‡Š

    # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–‡å­—ï¼ˆå¸¦æè¾¹æ•ˆæœï¼‰
    text_pos = ((clip_size[0] - text_width) / 2, clip_size[1] - text_height - 30)
    stroke_width = 2
    stroke_color = "black"
    draw.text((text_pos[0]-stroke_width, text_pos[1]), text, font=font, fill=stroke_color)
    draw.text((text_pos[0]+stroke_width, text_pos[1]), text, font=font, fill=stroke_color)
    draw.text((text_pos[0], text_pos[1]-stroke_width), text, font=font, fill=stroke_color)
    draw.text((text_pos[0], text_pos[1]+stroke_width), text, font=font, fill=stroke_color)
    draw.text(text_pos, text, font=font, fill=txt_color)

    # å°†Pillowå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œä»¥ä¾¿moviepyä½¿ç”¨
    cv_image = np.array(img)

    # åˆ›å»ºä¸€ä¸ª moviepy å‰ªè¾‘
    subtitle_clip = ImageClip(cv_image).set_duration(duration)
    return subtitle_clip

# --- è¾…åŠ©å‡½æ•°ï¼šä»ä¹‹å‰çš„è„šæœ¬ä¸­æå–å¹¶ä¼˜åŒ– ---

def _generate_srt_from_audio(audio_path: str, srt_path: str):
    """
    ä½¿ç”¨ Whisper æ¨¡å‹ä¸ºç»™å®šçš„éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆ SRT å­—å¹•ã€‚

    :param audio_path: è¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
    :param srt_path: è¾“å‡ºçš„ SRT æ–‡ä»¶è·¯å¾„ã€‚
    """
    print(f"--- å¼€å§‹ç”Ÿæˆå­—å¹•ï¼ŒéŸ³é¢‘æº: {audio_path} ---")
    try:
        # åŠ è½½æ¨¡å‹ (base æ¨¡å‹åœ¨æ€§èƒ½å’Œé€Ÿåº¦ä¸Šæ˜¯ä¸ªä¸é”™çš„èµ·ç‚¹)
        model = whisper.load_model("base")
        result = model.transcribe(audio_path, task="transcribe", language="en", fp16=False)

        def sec2timestamp(sec):
            h = int(sec // 3600)
            m = int((sec % 3600) // 60)
            s = int(sec % 60)
            ms = int((sec - int(sec)) * 1000)
            return f"{h:02}:{m:02}:{s:02},{ms:03}"

        # è¿™ä¸ªå‡½æ•°å°†çŸ­çš„å­—å¹•ç‰‡æ®µåˆå¹¶æˆæ›´æ˜“è¯»çš„å¥å­
        def merge_segments(segments, min_duration=2.0, max_chars=80):
            merged = []
            buffer = ""
            start_time = None
            end_time = None
            for i, seg in enumerate(segments):
                seg_text = seg['text'].strip()
                if not seg_text:
                    continue
                if start_time is None:
                    start_time = seg['start']

                buffer = (buffer + " " + seg_text) if buffer else seg_text
                end_time = seg['end']

                ends_with_punct = bool(re.search(r'[.!?ã€‚ï¼ï¼Ÿ]$', buffer.strip()))

                if (end_time - start_time >= min_duration) or (len(buffer) >= max_chars):
                    if ends_with_punct or len(buffer) >= max_chars:
                        merged.append({'start': start_time, 'end': end_time, 'text': buffer})
                        buffer = ""
                        start_time = None

            if buffer and start_time is not None:
                merged.append({'start': start_time, 'end': end_time, 'text': buffer})
            return merged

        merged_segments_data = merge_segments(result["segments"])

        with open(srt_path, "w", encoding="utf-8") as f:
            for i, seg in enumerate(merged_segments_data, 1):
                start = sec2timestamp(seg["start"])
                end = sec2timestamp(seg["end"])
                text = seg["text"].strip()
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")

        print(f"--- å­—å¹•æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ°: {srt_path} ---")
        return True
    except Exception as e:
        print(f"ç”Ÿæˆå­—å¹•æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return False


# --- ä¸»å‡½æ•°ï¼šæ•´åˆäº†å›¾ç‰‡ã€éŸ³é¢‘ã€å­—å¹•å’ŒGIF ---

def create_presentation_video(
        args,
        image_dir: str,
        tts_audio_files: dict,
        page_to_section_map: dict,
        output_video_path: str,
        overlay_gif_path: str = None,
        manim_video_path: str = None,
        font_path: str = "DejaVu-Sans-Mono",  # ä½¿ç”¨ä¸€ä¸ªæ›´é€šç”¨çš„å­—ä½“åç§°
        fps: int = 24
):
    """
    å°†ä¸€ç³»åˆ—å›¾ç‰‡ã€å¯¹åº”çš„éŸ³é¢‘å’Œå­—å¹•åˆæˆä¸ºä¸€ä¸ªå¸¦è§£è¯´çš„è§†é¢‘ã€‚

    :param image_dir: åŒ…å«å›¾ç‰‡æ–‡ä»¶ï¼ˆå¦‚ 0.png, 1.png ...ï¼‰çš„ç›®å½•ã€‚
    :param tts_audio_files: å­—å…¸ï¼Œé”®æ˜¯ç« èŠ‚åï¼Œå€¼æ˜¯å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
    :param page_to_section_map: å­—å…¸ï¼Œé”®æ˜¯å›¾ç‰‡é¡µç ï¼ˆæ•´æ•°ï¼‰ï¼Œå€¼æ˜¯å¯¹åº”çš„ç« èŠ‚åã€‚
    :param output_video_path: è¾“å‡ºè§†é¢‘çš„æ–‡ä»¶è·¯å¾„ã€‚
    :param fps: è§†é¢‘çš„å¸§ç‡ã€‚
    :param overlay_gif_path: (å¯é€‰) è¦å åŠ åœ¨å³ä¸‹è§’çš„GIFæ–‡ä»¶è·¯å¾„ã€‚
    :param font_path: (å¯é€‰) ç”¨äºå­—å¹•çš„å­—ä½“æ–‡ä»¶è·¯å¾„æˆ–å­—ä½“åç§°ã€‚
    """
    # ------------------ æ­¥éª¤ 1: å‡†å¤‡å·¥ä½œå’Œæ•°æ®æ ¡éªŒ ------------------
    print("==== å¼€å§‹è§†é¢‘ç”Ÿæˆæµç¨‹ ====")

    # è·å–å›¾ç‰‡æ–‡ä»¶å¹¶æ’åº
    try:
        image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]
        image_files.sort(key=lambda x: int(os.path.splitext(x)[0]))
        num_pages = len(image_files)
        print(f"æ‰¾åˆ° {num_pages} å¼ å›¾ç‰‡ã€‚")
    except (FileNotFoundError, ValueError) as e:
        print(f"é”™è¯¯: æ— æ³•å¤„ç†å›¾ç‰‡ç›®å½• '{image_dir}'. {e}")
        return

    # ------------------ æ–°å¢æ­¥éª¤: Manimè§†é¢‘æ’å…¥ç‚¹è®¡ç®— ------------------

    manim_insert_page = -1
    should_use_manim = args.use_manim and manim_video_path and os.path.exists(manim_video_path)
    if should_use_manim:
        implementation_pages = [p for p, s in page_to_section_map.items() if s == "Implementation"]
        if implementation_pages:
            manim_insert_page = max(implementation_pages) + 1
            print(f"Manimè§†é¢‘å°†è¢«æ’å…¥åœ¨ç¬¬ {manim_insert_page} é¡µçš„ä½ç½®ã€‚")
        else:
            print("è­¦å‘Š: æœªæ‰¾åˆ° 'Implementation' ç« èŠ‚ï¼Œæ— æ³•æ’å…¥Manimè§†é¢‘ã€‚")
            should_use_manim = False
    elif args.use_manim:
        print(f"è­¦å‘Š: Manimè§†é¢‘è·¯å¾„ '{manim_video_path}' æ— æ•ˆæˆ–æœªæä¾›ï¼Œå°†ä¸æ’å…¥è§†é¢‘ã€‚")
        should_use_manim = False

    # ------------------ æ­¥éª¤ 2: è®¡ç®—æ¯å¼ å¹»ç¯ç‰‡çš„æ—¶é•¿å¹¶åˆå¹¶éŸ³é¢‘ ------------------
    print("\n==== æ­¥éª¤ 2: è®¡ç®—æ—¶é•¿å¹¶åˆå¹¶éŸ³é¢‘ ====")
    slide_durations = [0] * num_pages
    tts_audio_clips = []
    section_usage_count = defaultdict(int)

    for page_num in range(num_pages):
        section_name = page_to_section_map.get(page_num)
        if section_name:
            section_usage_count[section_name] += 1

    # ä¿®å¤éŸ³é¢‘å¤„ç†é€»è¾‘
    section_audio_clips = {}  # ç¼“å­˜æ¯ä¸ªsectionçš„éŸ³é¢‘æ–‡ä»¶
    section_audio_positions = defaultdict(int)  # è·Ÿè¸ªæ¯ä¸ªsectionçš„éŸ³é¢‘ä½ç½®
    
    for i in range(num_pages):
        section_name = page_to_section_map.get(i)
        if not section_name or section_name not in tts_audio_files:
            print(f"è­¦å‘Š: ç¬¬ {i} é¡µæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚æˆ–éŸ³é¢‘ï¼Œå°†ä½¿ç”¨é»˜è®¤æ—¶é•¿ 3 ç§’ã€‚")
            slide_durations[i] = 3
            # æ·»åŠ ä¸€ä¸ªçŸ­é™éŸ³ç‰‡æ®µä»¥ä¿æŒåŒæ­¥
            tts_audio_clips.append(AudioClip(lambda t: 0, duration=3, fps=44100))
            continue

        audio_path = tts_audio_files[section_name]
        try:
            # ç¼“å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œé¿å…é‡å¤åŠ è½½
            if section_name not in section_audio_clips:
                section_audio_clips[section_name] = AudioFileClip(audio_path)
            
            audio_clip = section_audio_clips[section_name]
            total_duration = audio_clip.duration
            section_count = section_usage_count[section_name]
            
            # è®¡ç®—å½“å‰é¡µé¢åº”è¯¥ä½¿ç”¨çš„éŸ³é¢‘ç‰‡æ®µ
            segment_duration = total_duration / section_count
            start_time = section_audio_positions[section_name] * segment_duration
            end_time = start_time + segment_duration
            
            # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘é•¿åº¦
            if end_time > total_duration:
                end_time = total_duration
            
            # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
            audio_segment = audio_clip.subclip(start_time, end_time)
            actual_duration = audio_segment.duration
            slide_durations[i] = actual_duration
            tts_audio_clips.append(audio_segment)
            
            # æ›´æ–°ä½ç½®è®¡æ•°å™¨
            section_audio_positions[section_name] += 1
            
            print(f"é¡µé¢ {i} ({section_name}): åˆ†é…æ—¶é•¿ {actual_duration:.2f}s (ç‰‡æ®µ {section_audio_positions[section_name]}/{section_count})")
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶ {audio_path}ã€‚é”™è¯¯: {e}")
            slide_durations[i] = 3
            tts_audio_clips.append(AudioClip(lambda t: 0, duration=3, fps=44100))

    # åˆå¹¶TTSéŸ³é¢‘
    concatenated_tts_audio = concatenate_audioclips(tts_audio_clips)
    
    # å¦‚æœéœ€è¦ï¼Œæ’å…¥Manimçš„é™éŸ³ç‰‡æ®µ
    if should_use_manim:
        print("æ­£åœ¨å°†é™éŸ³ç‰‡æ®µæ’å…¥éŸ³é¢‘è½¨é“ä»¥åŒ¹é…Manimè§†é¢‘...")
        manim_clip_for_audio = VideoFileClip(manim_video_path)
        manim_duration = manim_clip_for_audio.duration
        silent_audio = AudioClip(lambda t: 0, duration=manim_duration, fps=44100)

        # è®¡ç®—éŸ³é¢‘æ’å…¥ç‚¹ï¼ˆä¿®å¤ï¼šä½¿ç”¨å®é™…çš„slide_durationsï¼‰
        audio_insertion_time = sum(slide_durations[:manim_insert_page])
        print(f"éŸ³é¢‘æ’å…¥ç‚¹: {audio_insertion_time:.2f}s")

        # åˆ†å‰²å¹¶é‡ç»„éŸ³é¢‘ï¼ˆä¿®å¤ï¼šç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘é•¿åº¦ï¼‰
        if audio_insertion_time < concatenated_tts_audio.duration:
            audio_part1 = concatenated_tts_audio.subclip(0, audio_insertion_time)
            audio_part2 = concatenated_tts_audio.subclip(audio_insertion_time)
            full_audio_track = concatenate_audioclips([audio_part1, silent_audio, audio_part2])
        else:
            # å¦‚æœæ’å…¥ç‚¹è¶…å‡ºéŸ³é¢‘é•¿åº¦ï¼Œç›´æ¥æ·»åŠ é™éŸ³
            full_audio_track = concatenate_audioclips([concatenated_tts_audio, silent_audio])
        
        manim_clip_for_audio.close()
    else:
        full_audio_track = concatenated_tts_audio

    total_duration = full_audio_track.duration
    print(f"éŸ³é¢‘è½¨é“æ„å»ºå®Œæˆï¼Œæ€»æ—¶é•¿: {total_duration:.2f}s")
    
    # éªŒè¯éŸ³é¢‘æ˜¯å¦æœ‰æ•ˆ
    if total_duration <= 0:
        print("âŒ é”™è¯¯: éŸ³é¢‘è½¨é“æ—¶é•¿ä¸º0ï¼Œå°†ä½¿ç”¨é™éŸ³")
        full_audio_track = AudioClip(lambda t: 0, duration=sum(slide_durations), fps=44100)

    # ------------------ æ­¥éª¤ 3: ç”Ÿæˆå­—å¹•æ–‡ä»¶ ------------------
    print("\n==== æ­¥éª¤ 3: ç”Ÿæˆå­—å¹• ====")
    temp_dir = "./temp_video_assets"
    os.makedirs(temp_dir, exist_ok=True)
    temp_audio_path = os.path.join(temp_dir, "full_audio.mp3")
    temp_srt_path = os.path.join(temp_dir, "subtitles.srt")

    # æ·»åŠ éŸ³é¢‘è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ”Š éŸ³é¢‘è°ƒè¯•ä¿¡æ¯:")
    print(f"   - éŸ³é¢‘è½¨é“æ—¶é•¿: {full_audio_track.duration:.2f}s")
    print(f"   - éŸ³é¢‘é‡‡æ ·ç‡: {full_audio_track.fps if hasattr(full_audio_track, 'fps') else 'N/A'}")
    print(f"   - ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {temp_audio_path}")
    
    # æ£€æŸ¥åŸå§‹TTSéŸ³é¢‘æ–‡ä»¶
    print(f"ğŸ” æ£€æŸ¥åŸå§‹TTSéŸ³é¢‘æ–‡ä»¶:")
    for section_name, audio_path in tts_audio_files.items():
        if os.path.exists(audio_path):
            file_size = os.path.getsize(audio_path)
            print(f"   - {section_name}: {file_size} bytes")
            
            # å°è¯•åŠ è½½å¹¶æ£€æŸ¥éŸ³é¢‘
        try:
            test_audio = AudioFileClip(audio_path)
            # ä¿®å¤ï¼šé€šè¿‡ä¼ é€’ä¸€ä¸ªæ˜ç¡®çš„æ—¶é—´æ®µæ¥è§„é¿ to_soundarray çš„ bug
            audio_array = test_audio.get_frame(t=0.1) # è·å–ä¸€ä¸ªæ ·æœ¬å¸§
            # æˆ‘ä»¬ä¸å†å°è¯•è¯»å–æ•´ä¸ªæ•°ç»„ï¼Œè€Œæ˜¯ç›´æ¥æ£€æŸ¥æ—¶é•¿
            print(f"     - æ—¶é•¿: {test_audio.duration:.2f}s (æŒ¯å¹…æ£€æŸ¥å·²è·³è¿‡)")
            test_audio.close()
        except Exception as e:
            print(f"     - æ— æ³•åŠ è½½éŸ³é¢‘: {e}")
            try:
                test_audio = AudioFileClip(audio_path)
                print(f"     - æ—¶é•¿: {test_audio.duration:.2f}s (æ— æ³•è·å–æŒ¯å¹…)")
                test_audio.close()
            except:
                print(f"     - å®Œå…¨æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶")
        else:
            print(f"   - {section_name}: æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é™éŸ³ï¼‰
        try:
            # æˆ‘ä»¬åœ¨è¿™é‡Œåªåšæœ€ç®€å•çš„æ£€æŸ¥ï¼Œå› ä¸ºä¸»è¦é—®é¢˜æ˜¯ to_soundarray
            if full_audio_track.duration > 0:
                print(f"ğŸ”Š éŸ³é¢‘è½¨é“æœ‰æ•ˆï¼Œæ—¶é•¿: {full_audio_track.duration:.2f}s")
                full_audio_track.write_audiofile(temp_audio_path)
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶å†™å…¥æˆåŠŸ: {temp_audio_path}")
            else:
                print("âŒ éŸ³é¢‘è½¨é“æ—¶é•¿ä¸º0")
                temp_audio_path = None
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
            temp_audio_path = None
            
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if temp_audio_path and os.path.exists(temp_audio_path):
            file_size = os.path.getsize(temp_audio_path)
            print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„åŒ…å«éŸ³é¢‘æ•°æ®
            if file_size < 1000:  # å°äº1KBå¯èƒ½æ˜¯ç©ºæ–‡ä»¶
                print("âš ï¸ è­¦å‘Š: éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘æ•°æ®")
        else:
            print("âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")
        temp_audio_path = None
    
    if temp_audio_path and os.path.exists(temp_audio_path):
        # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æœ‰å£°éŸ³
        try:
            import subprocess
            # ä½¿ç”¨ ffprobe æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
            result = subprocess.run(['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', temp_audio_path], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                duration = float(result.stdout.strip())
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶éªŒè¯æˆåŠŸï¼Œæ—¶é•¿: {duration:.2f}s")
                
                # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(temp_audio_path)
                if file_size > 10000:  # å¤§äº10KB
                    print(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤§å°æ­£å¸¸: {file_size} bytes")
                    
                    if not _generate_srt_from_audio(temp_audio_path, temp_srt_path):
                        print("å­—å¹•ç”Ÿæˆå¤±è´¥ï¼Œè§†é¢‘å°†ä¸åŒ…å«å­—å¹•ã€‚")
                        temp_srt_path = None
                else:
                    print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶å¤ªå°: {file_size} bytesï¼Œå¯èƒ½æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘")
                    temp_srt_path = None
            else:
                print("âŒ éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥")
                temp_srt_path = None
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶éªŒè¯å‡ºé”™: {e}")
            temp_srt_path = None
    else:
        print("âŒ æ— æ³•ç”Ÿæˆå­—å¹•ï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        temp_srt_path = None

    # ------------------ æ­¥éª¤ 4: ä»å›¾ç‰‡åˆ›å»ºè§†é¢‘å‰ªè¾‘ ------------------
    print("\n==== æ­¥éª¤ 4: åˆ›å»ºä¸»è§†é¢‘è½¨é“ ====")
    video_segments = []
    target_size = None  # ç”¨äºå­˜å‚¨å¹»ç¯ç‰‡çš„ç»Ÿä¸€å°ºå¯¸
    for i, image_file in enumerate(image_files):
        image_path = os.path.join(image_dir, image_file)
        clip = ImageClip(image_path).set_duration(slide_durations[i])
        if target_size is None:
            target_size = clip.size
            print(f"æ‰€æœ‰è§†é¢‘å‰ªè¾‘çš„ç›®æ ‡å°ºå¯¸è®¾ç½®ä¸º: {target_size}")
        video_segments.append(clip)

    if should_use_manim:
        print(f"æ­£åœ¨åŠ è½½Manimè§†é¢‘: {manim_video_path}")
        manim_clip = VideoFileClip(manim_video_path)
        if manim_clip.size != target_size and target_size is not None:
            print(f"æ­£åœ¨å°†Manimè§†é¢‘ä» {manim_clip.size} è°ƒæ•´åˆ° {target_size}")
            manim_clip = manim_clip.resize(target_size)
        video_segments.insert(manim_insert_page, manim_clip)

    main_clip = concatenate_videoclips(video_segments, method="compose")
    main_clip.fps = fps
    
    # ç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘æ—¶é•¿åŒ¹é…
    video_duration = main_clip.duration
    audio_duration = full_audio_track.duration
    
    print(f"è§†é¢‘æ—¶é•¿: {video_duration:.2f}s, éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}s")
    
    # å¦‚æœæ—¶é•¿ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´
    if abs(video_duration - audio_duration) > 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
        print(f"âš ï¸ éŸ³é¢‘å’Œè§†é¢‘æ—¶é•¿ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´...")
        if video_duration > audio_duration:
            # è§†é¢‘æ›´é•¿ï¼Œå»¶é•¿éŸ³é¢‘
            padding_duration = video_duration - audio_duration
            padding_audio = AudioClip(lambda t: 0, duration=padding_duration, fps=44100)
            full_audio_track = concatenate_audioclips([full_audio_track, padding_audio])
        else:
            # éŸ³é¢‘æ›´é•¿ï¼Œæˆªæ–­éŸ³é¢‘
            full_audio_track = full_audio_track.subclip(0, video_duration)
    
    main_clip = main_clip.set_audio(full_audio_track)  # å°†å®Œæ•´éŸ³è½¨é™„åŠ åˆ°è§†é¢‘
    
    # éªŒè¯æœ€ç»ˆéŸ³é¢‘
    print(f"ğŸ”Š æœ€ç»ˆéŸ³é¢‘éªŒè¯:")
    if main_clip.audio is not None:
        try:
            final_audio_array = main_clip.audio.to_soundarray(fps=44100, nbytes=2)
            if final_audio_array.size > 0:
                final_max_amp = np.max(np.abs(final_audio_array))
                print(f"   - æœ€ç»ˆéŸ³é¢‘æœ€å¤§æŒ¯å¹…: {final_max_amp:.6f}")
                print(f"   - æœ€ç»ˆéŸ³é¢‘æ—¶é•¿: {main_clip.audio.duration:.2f}s")
                
                if final_max_amp < 0.001:
                    print("âš ï¸ è­¦å‘Š: æœ€ç»ˆéŸ³é¢‘æŒ¯å¹…å¤ªå°ï¼Œå¯èƒ½å¬ä¸åˆ°å£°éŸ³")
                    # å°è¯•æ”¾å¤§æœ€ç»ˆéŸ³é¢‘
                    amplified_final_audio = main_clip.audio.volumex(5.0)
                    main_clip = main_clip.set_audio(amplified_final_audio)
                    print("âœ… æœ€ç»ˆéŸ³é¢‘å·²æ”¾å¤§5å€")
            else:
                print("   - æœ€ç»ˆéŸ³é¢‘æ•°ç»„ä¸ºç©º")
        except Exception as e:
            print(f"âŒ æ— æ³•éªŒè¯æœ€ç»ˆéŸ³é¢‘: {e}")
            print(f"   - æœ€ç»ˆéŸ³é¢‘æ—¶é•¿: {main_clip.audio.duration:.2f}s")
    else:
        print("âŒ æœ€ç»ˆè§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")

    # ------------------ æ­¥éª¤ 5: å åŠ å­—å¹•å’ŒGIF ------------------
    print("\n==== æ­¥éª¤ 5: å åŠ å­—å¹•å’Œå¯é€‰çš„GIF ====")
    clips_to_composite = [main_clip]

    # --- æ–°çš„å­—å¹•æ·»åŠ é€»è¾‘ (Plan B) ---
    if temp_srt_path and os.path.exists(temp_srt_path):
        print("æ­£åœ¨ä½¿ç”¨ OpenCV å’Œ Pillow æ·»åŠ å­—å¹•...")
        try:
            from moviepy.video.tools.subtitles import SubtitlesClip
            from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
            import pysrt # éœ€è¦å®‰è£…: pip install pysrt

            subs = pysrt.open(temp_srt_path)
            subtitle_clips = []
            for sub in subs:
                start_time = sub.start.to_time().hour * 3600 + sub.start.to_time().minute * 60 + sub.start.to_time().second + sub.start.to_time().microsecond / 1e6
                end_time = sub.end.to_time().hour * 3600 + sub.end.to_time().minute * 60 + sub.end.to_time().second + sub.end.to_time().microsecond / 1e6
                duration = end_time - start_time
                
                # ä½¿ç”¨æˆ‘ä»¬çš„æ–°å‡½æ•°åˆ›å»ºå‰ªè¾‘
                text_clip = create_subtitle_clip_opencv(
                    sub.text, 
                    duration, 
                    main_clip.size
                )
                
                # è®¾ç½®å‰ªè¾‘çš„å¼€å§‹æ—¶é—´å¹¶æ·»åŠ åˆ°åˆ—è¡¨
                subtitle_clips.append(text_clip.set_start(start_time))

            # å°†æ‰€æœ‰å­—å¹•å‰ªè¾‘å’Œä¸»è§†é¢‘åˆæˆä¸ºä¸€ä¸ª
            clips_to_composite.extend(subtitle_clips)
            print("âœ… å­—å¹•æ·»åŠ æˆåŠŸ (ä½¿ç”¨OpenCVæ–¹æ¡ˆ)")

        except Exception as e:
            print(f"âŒ ä½¿ç”¨OpenCVæ–¹æ¡ˆæ·»åŠ å­—å¹•æ—¶å¤±è´¥: {e}")

    # æ·»åŠ GIF
    if overlay_gif_path:
        print(f"æ­£åœ¨æ·»åŠ GIF: {overlay_gif_path}")
        try:
            # ä¿®æ­£: ä½¿ç”¨ imageio æ­£ç¡®è¯»å–GIFæ–‡ä»¶
            gif_reader = imageio.get_reader(overlay_gif_path)
            # ä»GIFå…ƒæ•°æ®è·å–fpsï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨è§†é¢‘çš„fps
            gif_fps = gif_reader.get_meta_data().get('fps', fps)
            gif_frames = [frame for frame in gif_reader]

            # ä»å¸§åˆ—è¡¨åˆ›å»ºå‰ªè¾‘
            gif_clip = ImageSequenceClip(gif_frames, fps=gif_fps)

            resized_gif = gif_clip.resize(height=main_clip.h * 0.25)  # GIFé«˜åº¦ä¸ºè§†é¢‘çš„25%
            looped_gif = resized_gif.fx(vfx.loop, duration=main_clip.duration)
            positioned_gif = looped_gif.set_position(("right", "bottom"))
            clips_to_composite.append(positioned_gif)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½æˆ–å¤„ç†GIF '{overlay_gif_path}'. é”™è¯¯: {e}")

    final_clip = CompositeVideoClip(clips_to_composite)
    # final_clip.set_duration(main_clip.duration)

    # ------------------ æ­¥éª¤ 6: å†™å…¥æœ€ç»ˆè§†é¢‘æ–‡ä»¶ ------------------
    print("\n==== æ­¥éª¤ 6: æ­£åœ¨å†™å…¥æœ€ç»ˆè§†é¢‘æ–‡ä»¶... (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´) ====")
    print(output_video_path, fps)
    # vvvv åœ¨è¿™é‡Œæ·»åŠ æœ€ç»ˆè°ƒè¯•ä»£ç  vvvv
    print("--- FINAL CLIP DEBUG INFO ---")
    print(f"Final clip duration = {final_clip.duration}")
    print(f"Final clip size (width, height) = {final_clip.size}")
    print(f"Has audio? {'Yes' if final_clip.audio is not None else 'No'}")
    if final_clip.audio is not None:
        print(f"Audio duration = {final_clip.audio.duration}")
    print("-----------------------------")
    # ^^^^ è°ƒè¯•ä»£ç ç»“æŸ ^^^^
    print('fps:', fps)
    final_clip = final_clip.set_audio(full_audio_track)
    final_clip.write_videofile(output_video_path,
                               codec="libx264",
                               audio_codec="aac",temp_audiofile='temp-audio.m4a', remove_temp=True,
                               threads=4, logger='bar')
    print(f"\nè§†é¢‘æˆåŠŸåˆ›å»ºï¼å·²ä¿å­˜è‡³ï¼š{output_video_path}")

    # print("æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    # full_audio_track.close()
    # for clip in tts_audio_clips:
    #     clip.close()
    # if os.path.exists(temp_audio_path): os.remove(temp_audio_path)
    # if os.path.exists(temp_srt_path): os.remove(temp_srt_path)
    # if os.path.exists(temp_dir): os.rmdir(temp_dir)


if __name__ == '__main__':
    # =================================================================
    # --- ä½¿ç”¨ç¤ºä¾‹ ---
    # å‡è®¾ä½ çš„å›¾ç‰‡åœ¨ './data/my_poster/images/' ç›®å½•ä¸‹ï¼Œå‘½åä¸º 0.png, 1.png ...
    # =================================================================

    # 1. å®šä¹‰ä½ çš„æ•°æ®ç»“æ„
    tts_audio_files_example = {
        "Poster Title & Author": "./contents/tts/section_01_Poster Title & Author.mp3",
        "Abstract": "./contents/tts/section_02_Abstract.mp3",
        "Introduction": "./contents/tts/section_03_Introduction.mp3",
        "Related Work": "./contents/tts/section_04_Related Work.mp3",
        "Methodology": "./contents/tts/section_05_Methodology.mp3",
        "Experimental Settings": "./contents/tts/section_06_Experimental Settings.mp3",
        "Experimental Results": "./contents/tts/section_07_Experimental Results.mp3",
        "Conclusion": "./contents/tts/section_08_Conclusion.mp3"
    }

    page_to_section_map_example = {
        0: 'Poster Title & Author',
        1: 'Abstract',
        2: 'Introduction',
        3: 'Related Work',
        4: 'Methodology',  # Methodologyçš„ç¬¬ä¸€é¡µ
        5: 'Methodology',  # Methodologyçš„ç¬¬äºŒé¡µ
        6: 'Experimental Settings',
        7: 'Experimental Results',
        8: 'Conclusion'
    }

    # 2. è®¾ç½®è·¯å¾„
    poster_name = "MyAwesomePoster"  # å®šä¹‰ä½ çš„é¡¹ç›®å
    image_directory = f'./data/{poster_name}/images'
    gif_file_path = f'./data/{poster_name}/kq.gif'  # å¦‚æœæ²¡æœ‰GIFï¼Œè®¾ä¸º None
    output_file_path = f'./output/{poster_name}_presentation.mp4'

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)

    # --- æ¨¡æ‹Ÿåˆ›å»ºä¸€äº›æ–‡ä»¶ç”¨äºæµ‹è¯• ---
    print("--- æ­£åœ¨åˆ›å»ºç”¨äºæµ‹è¯•çš„è™šæ‹Ÿæ–‡ä»¶ ---")
    os.makedirs(image_directory, exist_ok=True)
    for i in range(len(page_to_section_map_example)):
        # åˆ›å»ºç©ºç™½å›¾ç‰‡
        from PIL import Image

        img = Image.new('RGB', (1920, 1080), color='darkblue')
        img.save(os.path.join(image_directory, f'{i}.png'))

    os.makedirs("./contents/tts", exist_ok=True)
    for section, path in tts_audio_files_example.items():
        # åˆ›å»ºé™éŸ³éŸ³é¢‘
        from pydub import AudioSegment

        silence = AudioSegment.silent(duration=5000 if "Methodology" not in section else 10000)  # ç»™æ–¹æ³•è®ºæ›´é•¿çš„æ—¶é—´
        silence.export(path, format="mp3")
    print("--- è™šæ‹Ÿæ–‡ä»¶åˆ›å»ºå®Œæ¯• ---\n")
    # --- æ¨¡æ‹Ÿæ–‡ä»¶åˆ›å»ºç»“æŸ ---

    # 3. è°ƒç”¨ä¸»å‡½æ•°
    create_presentation_video(
        image_dir=image_directory,
        tts_audio_files=tts_audio_files_example,
        page_to_section_map=page_to_section_map_example,
        output_video_path=output_file_path,
        overlay_gif_path=None  # æš‚æ—¶ç¦ç”¨GIFæµ‹è¯•
        # overlay_gif_path=gif_file_path # å¦‚æœä½ æœ‰GIFæ–‡ä»¶ï¼Œè¯·å–æ¶ˆæ­¤è¡Œæ³¨é‡Š
    )

